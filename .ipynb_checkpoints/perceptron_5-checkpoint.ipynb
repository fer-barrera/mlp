{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a5a726-a07b-435f-a0ba-67837965b26c",
   "metadata": {},
   "source": [
    "# Perceptrón multicapa\n",
    "**MultiLayer Perceptron (MLP)**\n",
    "\n",
    "*Caso dos entradas y una salid*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f75e95e-6540-419d-84ae-eb79bc1ac3d8",
   "metadata": {},
   "source": [
    "## 1. Configuración e Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c9074-fd4a-4223-9bb3-276702970885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar estilo de gráficos\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfd71e8-54d2-48ab-b620-255fedf47d7b",
   "metadata": {},
   "source": [
    "## 2. Cargar el dataset de Iris y explorarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38dc59-4181-40d5-834e-597e4c0b2177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el dataset de Iris directamente desde scikit-learn\n",
    "iris = load_iris()\n",
    "\n",
    "# Extraemos las características (X) y las etiquetas (y)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convertimos a DataFrame para facilitar la exploración\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df['species'] = y\n",
    "\n",
    "# Vemos las primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f7602a-262d-45d6-9809-f01756e2e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploración rápida\n",
    "print(\"Dimensiones del DataFrame:\", df.shape)\n",
    "print(\"\\nDescripción estadística de las características:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Visualización básica: Pairplot\n",
    "sns.pairplot(df, hue='species', corner=True, diag_kind='hist')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bbde1a-3d16-4add-bfa0-2df41c4e2a8b",
   "metadata": {},
   "source": [
    "## 3. Separación de los datos en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f573c1-0966-419d-b6cf-c6988c27fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos en entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # para mantener la proporción de clases\n",
    ")\n",
    "\n",
    "print(\"Tamaño de X_train:\", X_train.shape)\n",
    "print(\"Tamaño de X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d228342-e46b-4a20-8b28-9a8e209f46ad",
   "metadata": {},
   "source": [
    "## 4. Crear y entrenar la red neuronal (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b22003c-67cd-480f-9bdc-2a2d9fa35ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos un Pipeline que escale los datos y luego entrene un MLPClassifier\n",
    "# Ajustamos parámetros básicos como número de neuronas en capas ocultas, \n",
    "# número máximo de iteraciones, etc.\n",
    "\n",
    "pipeline_mlp = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"mlp\", MLPClassifier(\n",
    "        hidden_layer_sizes=(10, 10),  # Dos capas ocultas con 10 neuronas cada una\n",
    "        activation='relu',           # Función de activación ReLU\n",
    "        solver='adam',               # Optimizador Adam\n",
    "        max_iter=1000,               # Máximo de iteraciones\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Entrenamos el pipeline\n",
    "pipeline_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7967569b-4c6c-485f-a2a8-c773c85c51b8",
   "metadata": {},
   "source": [
    "## 5. Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac8dcbe-0574-4f85-b1ed-fbca008a663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos predicciones con el conjunto de prueba\n",
    "y_pred = pipeline_mlp.predict(X_test)\n",
    "\n",
    "# Mostramos métricas de clasificación\n",
    "print(\"Reporte de Clasificación:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False,\n",
    "            xticklabels=iris.target_names,\n",
    "            yticklabels=iris.target_names)\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-kernel",
   "language": "python",
   "name": "ai-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
